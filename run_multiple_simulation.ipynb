{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulação simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_agent_basic.py', 'ps_agent_flexible.py', '__pycache__']\n",
      "['env_invasion_game.py', 'env_invasion_game_lier.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "agent_list = os.listdir('agents')\n",
    "environment_list = os.listdir('environments')\n",
    "\n",
    "print(agent_list)\n",
    "print(environment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'agents')\n",
    "sys.path.insert(0, 'environments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment\n",
    "import env_invasion_game\n",
    "\n",
    "#invasion_game requires no additional arguments\n",
    "env = env_invasion_game.TaskEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent\n",
    "import ps_agent_basic\n",
    "\n",
    "#parameters for the agent - explanations can be found in the comments inside the agent file\n",
    "gamma_damping = 0\n",
    "eta_glow_damping = 1\n",
    "policy_type = 'softmax'\n",
    "beta_softmax = 1\n",
    "num_reflections =  0\n",
    "\n",
    "agent = ps_agent_basic.BasicPSAgent(\n",
    "    env.num_actions, env.num_percepts_list, \n",
    "    gamma_damping, eta_glow_damping, \n",
    "    policy_type, beta_softmax, \n",
    "    num_reflections\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initialise and run interaction\"\"\"\n",
    "\n",
    "#set number of trials and maximum number of steps in each trial\n",
    "num_trials = 50\n",
    "max_steps_per_trial = 100 #This doesn't actually matter for invasion_game, which ends every trial after a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#initialise a record of performance\n",
    "learning_curve = np.zeros(num_trials)\n",
    "reward = 0 #temporarily stores the reward for the most recent action\n",
    "for i_trial in range(num_trials):\n",
    "    reward_trial = 0 #additive couSSSSSSnter of the total rewards earned during the current trial\n",
    "    discretized_observation = env.reset()\n",
    "    for t in range(max_steps_per_trial):\n",
    "        #This is where the heart of the interaction takes place\n",
    "        action = agent.deliberate_and_learn(discretized_observation, reward)\n",
    "        discretized_observation, reward, done = env.move(action)\n",
    "        reward_trial += reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    learning_curve[i_trial] = float(reward_trial)/(t+1)\n",
    "\n",
    "\"\"\"Return results\"\"\"\n",
    "print(learning_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulando parâmetros - agente básico - gamma_damping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_agent_basic.py', 'ps_agent_flexible.py', '__pycache__']\n",
      "['env_invasion_game.py', 'env_invasion_game_lier.py', 'env_neverending_color.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "agent_list = os.listdir('agents')\n",
    "environment_list = os.listdir('environments')\n",
    "\n",
    "print(agent_list)\n",
    "print(environment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'agents')\n",
    "sys.path.insert(0, 'environments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment\n",
    "import env_invasion_game_lier as environment_class\n",
    "\n",
    "#invasion_game requires no additional arguments\n",
    "env = environment_class.TaskEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent\n",
    "import ps_agent_basic\n",
    "\n",
    "#parameters for the agent - explanations can be found in the comments inside the agent file\n",
    "gamma_damping = 0\n",
    "eta_glow_damping = 0.7\n",
    "policy_type = 'softmax'\n",
    "beta_softmax = 1\n",
    "num_reflections =  0\n",
    "\n",
    "db = pd.DataFrame() # guarda as informações da simulação\n",
    "for gamma_damping in [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "  for episode in range(0,10):\n",
    "    #env = environment_class.TaskEnvironment(2, 1, num_trials)\n",
    "    env = environment_class.TaskEnvironment()\n",
    "    agent = ps_agent_basic.BasicPSAgent(\n",
    "        env.num_actions, env.num_percepts_list, \n",
    "        gamma_damping, eta_glow_damping, \n",
    "        policy_type, beta_softmax, \n",
    "        num_reflections\n",
    "    )\n",
    "    \n",
    "    #initialise a record of performance\n",
    "    learning_curve = []\n",
    "    reward = 0 #temporarily stores the reward for the most recent action\n",
    "    for i_trial in range(num_trials):\n",
    "        reward_trial = 0 #additive counter of the total rewards earned during the current trial\n",
    "        discretized_observation = env.reset()\n",
    "        for t in range(max_steps_per_trial):\n",
    "            #This is where the heart of the interaction takes place\n",
    "            action = agent.deliberate_and_learn(discretized_observation, reward)\n",
    "            discretized_observation, reward, done = env.move(action)\n",
    "            reward_trial += reward\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        learning_curve.append([i_trial+1, episode + 1, float(reward_trial)/(t+1), gamma_damping, eta_glow_damping, discretized_observation, action])\n",
    "\n",
    "    _ = pd.DataFrame(learning_curve, columns = ['rodada','episode','reward','gamma_damping','eta_glow_damping','observation','action'])\n",
    "    _['blocking_efficiency'] = _['reward'].cumsum()/(_['rodada'])\n",
    "    db = pd.concat([db,_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rodada</th>\n",
       "      <th>episode</th>\n",
       "      <th>reward</th>\n",
       "      <th>gamma_damping</th>\n",
       "      <th>eta_glow_damping</th>\n",
       "      <th>observation</th>\n",
       "      <th>action</th>\n",
       "      <th>blocking_efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rodada  episode  reward  gamma_damping  eta_glow_damping observation  \\\n",
       "0       1        1     1.0            0.0               0.7      [1, 0]   \n",
       "1       2        1     1.0            0.0               0.7      [1, 0]   \n",
       "2       3        1     0.0            0.0               0.7      [1, 1]   \n",
       "3       4        1     0.0            0.0               0.7      [0, 1]   \n",
       "4       5        1     1.0            0.0               0.7      [0, 1]   \n",
       "5       6        1     1.0            0.0               0.7      [1, 1]   \n",
       "6       7        1     1.0            0.0               0.7      [0, 0]   \n",
       "7       8        1     1.0            0.0               0.7      [0, 1]   \n",
       "8       9        1     1.0            0.0               0.7      [0, 0]   \n",
       "9      10        1     1.0            0.0               0.7      [1, 1]   \n",
       "\n",
       "   action  blocking_efficiency  \n",
       "0       0             1.000000  \n",
       "1       1             1.000000  \n",
       "2       0             0.666667  \n",
       "3       1             0.500000  \n",
       "4       1             0.600000  \n",
       "5       1             0.666667  \n",
       "6       0             0.714286  \n",
       "7       0             0.750000  \n",
       "8       1             0.777778  \n",
       "9       0             0.800000  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-e5a933fe0fbf4f51b2b2bbefb9479243.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-e5a933fe0fbf4f51b2b2bbefb9479243.vega-embed details,\n",
       "  #altair-viz-e5a933fe0fbf4f51b2b2bbefb9479243.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-e5a933fe0fbf4f51b2b2bbefb9479243\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-e5a933fe0fbf4f51b2b2bbefb9479243\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-e5a933fe0fbf4f51b2b2bbefb9479243\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-bc0b09ae7d9c00b0b94e285eb90b3e19\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"color\": {\"field\": \"gamma_damping\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"gamma_damping\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"rodada\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"blocking_efficiency\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-bc0b09ae7d9c00b0b94e285eb90b3e19\": [{\"rodada\": 1, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.2}, {\"rodada\": 1, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6}, {\"rodada\": 1, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.8}, {\"rodada\": 1, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5}, {\"rodada\": 1, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6}, {\"rodada\": 1, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.3}, {\"rodada\": 1, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 1, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.6}, {\"rodada\": 1, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.3}, {\"rodada\": 1, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5}, {\"rodada\": 1, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.6}, {\"rodada\": 2, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.3}, {\"rodada\": 2, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.55}, {\"rodada\": 2, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.7}, {\"rodada\": 2, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6}, {\"rodada\": 2, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.55}, {\"rodada\": 2, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.35}, {\"rodada\": 2, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.55}, {\"rodada\": 2, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.6}, {\"rodada\": 2, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.45}, {\"rodada\": 2, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.6}, {\"rodada\": 2, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5}, {\"rodada\": 3, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.3333333333333333}, {\"rodada\": 3, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5333333333333333}, {\"rodada\": 3, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6333333333333333}, {\"rodada\": 3, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5333333333333333}, {\"rodada\": 3, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6}, {\"rodada\": 3, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.4}, {\"rodada\": 3, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 3, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.6333333333333333}, {\"rodada\": 3, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 3, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 3, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.4333333333333333}, {\"rodada\": 4, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.3}, {\"rodada\": 4, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.55}, {\"rodada\": 4, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6}, {\"rodada\": 4, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.55}, {\"rodada\": 4, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.625}, {\"rodada\": 4, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.375}, {\"rodada\": 4, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.65}, {\"rodada\": 4, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.525}, {\"rodada\": 4, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.575}, {\"rodada\": 4, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.575}, {\"rodada\": 4, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.425}, {\"rodada\": 5, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.42000000000000004}, {\"rodada\": 5, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5}, {\"rodada\": 5, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.62}, {\"rodada\": 5, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6}, {\"rodada\": 5, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.64}, {\"rodada\": 5, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.44000000000000006}, {\"rodada\": 5, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.62}, {\"rodada\": 5, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5}, {\"rodada\": 5, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.58}, {\"rodada\": 5, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.6}, {\"rodada\": 5, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.42000000000000004}, {\"rodada\": 6, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.45}, {\"rodada\": 6, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.4666666666666667}, {\"rodada\": 6, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6}, {\"rodada\": 6, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6166666666666667}, {\"rodada\": 6, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6}, {\"rodada\": 6, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5}, {\"rodada\": 6, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 6, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5166666666666666}, {\"rodada\": 6, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 6, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.6}, {\"rodada\": 6, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.4333333333333333}, {\"rodada\": 7, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.4714285714285714}, {\"rodada\": 7, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5}, {\"rodada\": 7, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6142857142857142}, {\"rodada\": 7, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6142857142857142}, {\"rodada\": 7, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5857142857142856}, {\"rodada\": 7, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.4714285714285714}, {\"rodada\": 7, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5857142857142856}, {\"rodada\": 7, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5571428571428572}, {\"rodada\": 7, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5571428571428572}, {\"rodada\": 7, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5714285714285714}, {\"rodada\": 7, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.45714285714285713}, {\"rodada\": 8, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.5375}, {\"rodada\": 8, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.4875}, {\"rodada\": 8, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6375}, {\"rodada\": 8, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.575}, {\"rodada\": 8, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5875}, {\"rodada\": 8, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.4875}, {\"rodada\": 8, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5875}, {\"rodada\": 8, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.55}, {\"rodada\": 8, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.6}, {\"rodada\": 8, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5625}, {\"rodada\": 8, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.475}, {\"rodada\": 9, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.5888888888888888}, {\"rodada\": 9, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.47777777777777775}, {\"rodada\": 9, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6444444444444445}, {\"rodada\": 9, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6}, {\"rodada\": 9, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6}, {\"rodada\": 9, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.47777777777777775}, {\"rodada\": 9, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 9, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5444444444444445}, {\"rodada\": 9, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.6222222222222222}, {\"rodada\": 9, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5555555555555556}, {\"rodada\": 9, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.47777777777777775}, {\"rodada\": 10, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.62}, {\"rodada\": 10, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.49000000000000005}, {\"rodada\": 10, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6599999999999999}, {\"rodada\": 10, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6}, {\"rodada\": 10, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6}, {\"rodada\": 10, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5}, {\"rodada\": 10, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 10, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5599999999999999}, {\"rodada\": 10, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.6100000000000001}, {\"rodada\": 10, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5700000000000001}, {\"rodada\": 10, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.48999999999999994}, {\"rodada\": 11, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.6272727272727272}, {\"rodada\": 11, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.4727272727272728}, {\"rodada\": 11, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6636363636363637}, {\"rodada\": 11, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6181818181818182}, {\"rodada\": 11, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5909090909090909}, {\"rodada\": 11, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5181818181818182}, {\"rodada\": 11, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 11, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5727272727272728}, {\"rodada\": 11, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5818181818181818}, {\"rodada\": 11, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5545454545454545}, {\"rodada\": 11, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5}, {\"rodada\": 12, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.625}, {\"rodada\": 12, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.4833333333333333}, {\"rodada\": 12, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.675}, {\"rodada\": 12, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6083333333333333}, {\"rodada\": 12, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5833333333333333}, {\"rodada\": 12, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.525}, {\"rodada\": 12, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5916666666666667}, {\"rodada\": 12, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.6}, {\"rodada\": 12, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5833333333333333}, {\"rodada\": 12, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.55}, {\"rodada\": 12, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5}, {\"rodada\": 13, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.6461538461538462}, {\"rodada\": 13, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5076923076923078}, {\"rodada\": 13, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6615384615384616}, {\"rodada\": 13, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6230769230769231}, {\"rodada\": 13, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5923076923076923}, {\"rodada\": 13, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5307692307692308}, {\"rodada\": 13, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5846153846153846}, {\"rodada\": 13, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.6}, {\"rodada\": 13, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5769230769230769}, {\"rodada\": 13, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5538461538461539}, {\"rodada\": 13, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5}, {\"rodada\": 14, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.65}, {\"rodada\": 14, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5142857142857142}, {\"rodada\": 14, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6714285714285715}, {\"rodada\": 14, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6142857142857143}, {\"rodada\": 14, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5928571428571429}, {\"rodada\": 14, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5214285714285715}, {\"rodada\": 14, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5642857142857143}, {\"rodada\": 14, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5857142857142857}, {\"rodada\": 14, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5714285714285714}, {\"rodada\": 14, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5642857142857143}, {\"rodada\": 14, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5142857142857142}, {\"rodada\": 15, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.6666666666666666}, {\"rodada\": 15, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5466666666666666}, {\"rodada\": 15, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6866666666666666}, {\"rodada\": 15, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6066666666666667}, {\"rodada\": 15, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5933333333333334}, {\"rodada\": 15, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.52}, {\"rodada\": 15, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 15, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5866666666666667}, {\"rodada\": 15, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.58}, {\"rodada\": 15, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 15, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5333333333333333}, {\"rodada\": 16, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.68125}, {\"rodada\": 16, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.55625}, {\"rodada\": 16, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.68125}, {\"rodada\": 16, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.60625}, {\"rodada\": 16, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5875}, {\"rodada\": 16, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5375}, {\"rodada\": 16, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.575}, {\"rodada\": 16, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.56875}, {\"rodada\": 16, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.58125}, {\"rodada\": 16, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.56875}, {\"rodada\": 16, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.54375}, {\"rodada\": 17, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.7}, {\"rodada\": 17, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5647058823529412}, {\"rodada\": 17, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6823529411764706}, {\"rodada\": 17, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6176470588235294}, {\"rodada\": 17, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5823529411764705}, {\"rodada\": 17, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5411764705882354}, {\"rodada\": 17, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5764705882352941}, {\"rodada\": 17, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5588235294117647}, {\"rodada\": 17, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5705882352941176}, {\"rodada\": 17, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5588235294117647}, {\"rodada\": 17, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5411764705882354}, {\"rodada\": 18, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.711111111111111}, {\"rodada\": 18, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5777777777777777}, {\"rodada\": 18, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6777777777777778}, {\"rodada\": 18, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.611111111111111}, {\"rodada\": 18, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5833333333333334}, {\"rodada\": 18, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5444444444444445}, {\"rodada\": 18, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5888888888888889}, {\"rodada\": 18, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5444444444444445}, {\"rodada\": 18, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5611111111111111}, {\"rodada\": 18, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5611111111111111}, {\"rodada\": 18, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5444444444444445}, {\"rodada\": 19, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.7210526315789474}, {\"rodada\": 19, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.5894736842105263}, {\"rodada\": 19, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6736842105263158}, {\"rodada\": 19, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.6}, {\"rodada\": 19, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5894736842105263}, {\"rodada\": 19, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5421052631578946}, {\"rodada\": 19, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5947368421052632}, {\"rodada\": 19, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5421052631578946}, {\"rodada\": 19, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5526315789473684}, {\"rodada\": 19, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5421052631578946}, {\"rodada\": 19, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5473684210526316}, {\"rodada\": 20, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.735}, {\"rodada\": 20, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.605}, {\"rodada\": 20, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6849999999999999}, {\"rodada\": 20, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.595}, {\"rodada\": 20, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5900000000000001}, {\"rodada\": 20, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.53}, {\"rodada\": 20, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5850000000000001}, {\"rodada\": 20, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.535}, {\"rodada\": 20, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.55}, {\"rodada\": 20, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.545}, {\"rodada\": 20, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5599999999999999}, {\"rodada\": 21, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.7428571428571429}, {\"rodada\": 21, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6238095238095238}, {\"rodada\": 21, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.680952380952381}, {\"rodada\": 21, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5904761904761905}, {\"rodada\": 21, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5952380952380952}, {\"rodada\": 21, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5238095238095238}, {\"rodada\": 21, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5952380952380952}, {\"rodada\": 21, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5333333333333333}, {\"rodada\": 21, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5619047619047619}, {\"rodada\": 21, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5523809523809524}, {\"rodada\": 21, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5523809523809524}, {\"rodada\": 22, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.7545454545454546}, {\"rodada\": 22, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6363636363636364}, {\"rodada\": 22, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6863636363636363}, {\"rodada\": 22, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5909090909090909}, {\"rodada\": 22, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6}, {\"rodada\": 22, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5318181818181819}, {\"rodada\": 22, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 22, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5409090909090909}, {\"rodada\": 22, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5590909090909091}, {\"rodada\": 22, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5454545454545454}, {\"rodada\": 22, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5545454545454546}, {\"rodada\": 23, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.7652173913043478}, {\"rodada\": 23, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6434782608695653}, {\"rodada\": 23, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6782608695652174}, {\"rodada\": 23, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5869565217391305}, {\"rodada\": 23, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6043478260869566}, {\"rodada\": 23, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5347826086956522}, {\"rodada\": 23, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.608695652173913}, {\"rodada\": 23, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5391304347826087}, {\"rodada\": 23, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5652173913043479}, {\"rodada\": 23, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5521739130434782}, {\"rodada\": 23, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5565217391304348}, {\"rodada\": 24, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.775}, {\"rodada\": 24, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6583333333333333}, {\"rodada\": 24, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6791666666666666}, {\"rodada\": 24, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5791666666666667}, {\"rodada\": 24, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6125}, {\"rodada\": 24, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5333333333333333}, {\"rodada\": 24, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 24, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5333333333333333}, {\"rodada\": 24, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 24, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5625}, {\"rodada\": 24, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.55}, {\"rodada\": 25, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.784}, {\"rodada\": 25, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.664}, {\"rodada\": 25, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6799999999999999}, {\"rodada\": 25, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.58}, {\"rodada\": 25, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.62}, {\"rodada\": 25, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.532}, {\"rodada\": 25, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.6}, {\"rodada\": 25, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.528}, {\"rodada\": 25, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5599999999999999}, {\"rodada\": 25, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5680000000000001}, {\"rodada\": 25, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.556}, {\"rodada\": 26, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.7923076923076924}, {\"rodada\": 26, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6730769230769231}, {\"rodada\": 26, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.676923076923077}, {\"rodada\": 26, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.573076923076923}, {\"rodada\": 26, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6230769230769231}, {\"rodada\": 26, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5307692307692308}, {\"rodada\": 26, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5961538461538461}, {\"rodada\": 26, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5230769230769231}, {\"rodada\": 26, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5615384615384615}, {\"rodada\": 26, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5692307692307692}, {\"rodada\": 26, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5576923076923077}, {\"rodada\": 27, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.7962962962962963}, {\"rodada\": 27, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6814814814814815}, {\"rodada\": 27, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6814814814814815}, {\"rodada\": 27, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 27, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6296296296296295}, {\"rodada\": 27, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5259259259259259}, {\"rodada\": 27, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5888888888888888}, {\"rodada\": 27, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5333333333333333}, {\"rodada\": 27, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5555555555555556}, {\"rodada\": 27, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5740740740740741}, {\"rodada\": 27, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.562962962962963}, {\"rodada\": 28, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8035714285714286}, {\"rodada\": 28, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6785714285714286}, {\"rodada\": 28, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6821428571428572}, {\"rodada\": 28, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5714285714285714}, {\"rodada\": 28, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6285714285714286}, {\"rodada\": 28, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.525}, {\"rodada\": 28, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5785714285714285}, {\"rodada\": 28, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.525}, {\"rodada\": 28, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5607142857142857}, {\"rodada\": 28, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5714285714285714}, {\"rodada\": 28, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5678571428571428}, {\"rodada\": 29, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8068965517241379}, {\"rodada\": 29, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6862068965517241}, {\"rodada\": 29, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6689655172413793}, {\"rodada\": 29, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5724137931034482}, {\"rodada\": 29, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6310344827586206}, {\"rodada\": 29, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5310344827586208}, {\"rodada\": 29, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5689655172413793}, {\"rodada\": 29, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5344827586206897}, {\"rodada\": 29, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5655172413793104}, {\"rodada\": 29, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5689655172413793}, {\"rodada\": 29, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5689655172413793}, {\"rodada\": 30, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8133333333333332}, {\"rodada\": 30, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6900000000000001}, {\"rodada\": 30, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6666666666666667}, {\"rodada\": 30, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 30, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.63}, {\"rodada\": 30, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5233333333333333}, {\"rodada\": 30, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5733333333333334}, {\"rodada\": 30, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5366666666666666}, {\"rodada\": 30, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5633333333333332}, {\"rodada\": 30, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5633333333333332}, {\"rodada\": 30, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5700000000000001}, {\"rodada\": 31, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8193548387096774}, {\"rodada\": 31, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.6967741935483871}, {\"rodada\": 31, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.667741935483871}, {\"rodada\": 31, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5645161290322581}, {\"rodada\": 31, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6225806451612903}, {\"rodada\": 31, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5258064516129032}, {\"rodada\": 31, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5806451612903226}, {\"rodada\": 31, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.535483870967742}, {\"rodada\": 31, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.564516129032258}, {\"rodada\": 31, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.564516129032258}, {\"rodada\": 31, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.567741935483871}, {\"rodada\": 32, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.825}, {\"rodada\": 32, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7}, {\"rodada\": 32, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.675}, {\"rodada\": 32, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.559375}, {\"rodada\": 32, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.609375}, {\"rodada\": 32, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.53125}, {\"rodada\": 32, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.578125}, {\"rodada\": 32, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.53125}, {\"rodada\": 32, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.56875}, {\"rodada\": 32, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.559375}, {\"rodada\": 32, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.56875}, {\"rodada\": 33, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8303030303030303}, {\"rodada\": 33, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7}, {\"rodada\": 33, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6696969696969697}, {\"rodada\": 33, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5575757575757576}, {\"rodada\": 33, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6090909090909091}, {\"rodada\": 33, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5333333333333333}, {\"rodada\": 33, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5727272727272728}, {\"rodada\": 33, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5242424242424242}, {\"rodada\": 33, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 33, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5575757575757576}, {\"rodada\": 33, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5636363636363637}, {\"rodada\": 34, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8323529411764706}, {\"rodada\": 34, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7058823529411764}, {\"rodada\": 34, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6735294117647059}, {\"rodada\": 34, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5529411764705883}, {\"rodada\": 34, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6088235294117648}, {\"rodada\": 34, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5294117647058824}, {\"rodada\": 34, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5705882352941176}, {\"rodada\": 34, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5235294117647059}, {\"rodada\": 34, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5617647058823529}, {\"rodada\": 34, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5617647058823529}, {\"rodada\": 34, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5647058823529412}, {\"rodada\": 35, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8342857142857143}, {\"rodada\": 35, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7114285714285714}, {\"rodada\": 35, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6771428571428572}, {\"rodada\": 35, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5542857142857143}, {\"rodada\": 35, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6028571428571429}, {\"rodada\": 35, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5285714285714286}, {\"rodada\": 35, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5714285714285714}, {\"rodada\": 35, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5285714285714286}, {\"rodada\": 35, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5657142857142856}, {\"rodada\": 35, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5571428571428572}, {\"rodada\": 35, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5599999999999999}, {\"rodada\": 36, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8388888888888889}, {\"rodada\": 36, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7166666666666667}, {\"rodada\": 36, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.675}, {\"rodada\": 36, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5472222222222223}, {\"rodada\": 36, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.6}, {\"rodada\": 36, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5277777777777778}, {\"rodada\": 36, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5722222222222222}, {\"rodada\": 36, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5361111111111112}, {\"rodada\": 36, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5694444444444444}, {\"rodada\": 36, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5583333333333333}, {\"rodada\": 36, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 37, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8432432432432433}, {\"rodada\": 37, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7189189189189189}, {\"rodada\": 37, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6783783783783784}, {\"rodada\": 37, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5459459459459459}, {\"rodada\": 37, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5891891891891892}, {\"rodada\": 37, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5297297297297298}, {\"rodada\": 37, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5621621621621622}, {\"rodada\": 37, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5351351351351352}, {\"rodada\": 37, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5648648648648649}, {\"rodada\": 37, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5594594594594595}, {\"rodada\": 37, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5702702702702702}, {\"rodada\": 38, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8473684210526315}, {\"rodada\": 38, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7263157894736842}, {\"rodada\": 38, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6815789473684211}, {\"rodada\": 38, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5473684210526316}, {\"rodada\": 38, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5868421052631578}, {\"rodada\": 38, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5289473684210526}, {\"rodada\": 38, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5605263157894737}, {\"rodada\": 38, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5342105263157895}, {\"rodada\": 38, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5657894736842105}, {\"rodada\": 38, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5578947368421052}, {\"rodada\": 38, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5684210526315789}, {\"rodada\": 39, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8512820512820513}, {\"rodada\": 39, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7307692307692307}, {\"rodada\": 39, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6871794871794872}, {\"rodada\": 39, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5538461538461539}, {\"rodada\": 39, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5846153846153845}, {\"rodada\": 39, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5282051282051282}, {\"rodada\": 39, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.558974358974359}, {\"rodada\": 39, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5282051282051282}, {\"rodada\": 39, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5615384615384615}, {\"rodada\": 39, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5512820512820513}, {\"rodada\": 39, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5692307692307692}, {\"rodada\": 40, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8525}, {\"rodada\": 40, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.735}, {\"rodada\": 40, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6900000000000001}, {\"rodada\": 40, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5599999999999999}, {\"rodada\": 40, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5775}, {\"rodada\": 40, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5325}, {\"rodada\": 40, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5525}, {\"rodada\": 40, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5325}, {\"rodada\": 40, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5625}, {\"rodada\": 40, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5475}, {\"rodada\": 40, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5675}, {\"rodada\": 41, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8560975609756097}, {\"rodada\": 41, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7414634146341463}, {\"rodada\": 41, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6902439024390243}, {\"rodada\": 41, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5609756097560975}, {\"rodada\": 41, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5756097560975609}, {\"rodada\": 41, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5341463414634147}, {\"rodada\": 41, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5536585365853659}, {\"rodada\": 41, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5365853658536586}, {\"rodada\": 41, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5634146341463415}, {\"rodada\": 41, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5512195121951219}, {\"rodada\": 41, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5634146341463414}, {\"rodada\": 42, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8571428571428571}, {\"rodada\": 42, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7476190476190476}, {\"rodada\": 42, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6928571428571428}, {\"rodada\": 42, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5619047619047619}, {\"rodada\": 42, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5761904761904761}, {\"rodada\": 42, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5404761904761906}, {\"rodada\": 42, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5547619047619048}, {\"rodada\": 42, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5357142857142857}, {\"rodada\": 42, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 42, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5476190476190477}, {\"rodada\": 42, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5666666666666667}, {\"rodada\": 43, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8604651162790697}, {\"rodada\": 43, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7534883720930232}, {\"rodada\": 43, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6953488372093023}, {\"rodada\": 43, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5651162790697675}, {\"rodada\": 43, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5790697674418605}, {\"rodada\": 43, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5395348837209302}, {\"rodada\": 43, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5604651162790698}, {\"rodada\": 43, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.530232558139535}, {\"rodada\": 43, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5604651162790698}, {\"rodada\": 43, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5465116279069767}, {\"rodada\": 43, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5651162790697675}, {\"rodada\": 44, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8636363636363636}, {\"rodada\": 44, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7545454545454546}, {\"rodada\": 44, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6954545454545454}, {\"rodada\": 44, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.575}, {\"rodada\": 44, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5795454545454546}, {\"rodada\": 44, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5386363636363637}, {\"rodada\": 44, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5659090909090909}, {\"rodada\": 44, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5318181818181819}, {\"rodada\": 44, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5636363636363637}, {\"rodada\": 44, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5454545454545455}, {\"rodada\": 44, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5636363636363637}, {\"rodada\": 45, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8666666666666666}, {\"rodada\": 45, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.76}, {\"rodada\": 45, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6955555555555556}, {\"rodada\": 45, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5755555555555556}, {\"rodada\": 45, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5822222222222222}, {\"rodada\": 45, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.54}, {\"rodada\": 45, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5688888888888889}, {\"rodada\": 45, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5311111111111111}, {\"rodada\": 45, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5622222222222222}, {\"rodada\": 45, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5399999999999999}, {\"rodada\": 45, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5622222222222222}, {\"rodada\": 46, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8673913043478262}, {\"rodada\": 46, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7630434782608695}, {\"rodada\": 46, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6956521739130435}, {\"rodada\": 46, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5782608695652174}, {\"rodada\": 46, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5847826086956521}, {\"rodada\": 46, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5456521739130434}, {\"rodada\": 46, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5717391304347826}, {\"rodada\": 46, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5369565217391304}, {\"rodada\": 46, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5630434782608695}, {\"rodada\": 46, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5391304347826087}, {\"rodada\": 46, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5543478260869565}, {\"rodada\": 47, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8702127659574469}, {\"rodada\": 47, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7659574468085106}, {\"rodada\": 47, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6957446808510638}, {\"rodada\": 47, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5829787234042553}, {\"rodada\": 47, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5914893617021277}, {\"rodada\": 47, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.548936170212766}, {\"rodada\": 47, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5680851063829787}, {\"rodada\": 47, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5382978723404255}, {\"rodada\": 47, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5553191489361702}, {\"rodada\": 47, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5425531914893618}, {\"rodada\": 47, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5574468085106383}, {\"rodada\": 48, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8729166666666666}, {\"rodada\": 48, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7708333333333333}, {\"rodada\": 48, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6979166666666667}, {\"rodada\": 48, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5854166666666667}, {\"rodada\": 48, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.59375}, {\"rodada\": 48, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5520833333333333}, {\"rodada\": 48, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5645833333333333}, {\"rodada\": 48, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.5395833333333333}, {\"rodada\": 48, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5604166666666667}, {\"rodada\": 48, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.54375}, {\"rodada\": 48, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5583333333333333}, {\"rodada\": 49, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.8734693877551021}, {\"rodada\": 49, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.7714285714285715}, {\"rodada\": 49, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.6979591836734694}, {\"rodada\": 49, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5877551020408164}, {\"rodada\": 49, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.5959183673469388}, {\"rodada\": 49, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5530612244897959}, {\"rodada\": 49, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5673469387755101}, {\"rodada\": 49, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.536734693877551}, {\"rodada\": 49, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.5591836734693878}, {\"rodada\": 49, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.5408163265306123}, {\"rodada\": 49, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.5612244897959184}, {\"rodada\": 50, \"gamma_damping\": 0.0, \"blocking_efficiency\": 0.876}, {\"rodada\": 50, \"gamma_damping\": 0.1, \"blocking_efficiency\": 0.772}, {\"rodada\": 50, \"gamma_damping\": 0.2, \"blocking_efficiency\": 0.702}, {\"rodada\": 50, \"gamma_damping\": 0.3, \"blocking_efficiency\": 0.5900000000000001}, {\"rodada\": 50, \"gamma_damping\": 0.4, \"blocking_efficiency\": 0.596}, {\"rodada\": 50, \"gamma_damping\": 0.5, \"blocking_efficiency\": 0.5519999999999999}, {\"rodada\": 50, \"gamma_damping\": 0.6, \"blocking_efficiency\": 0.5660000000000001}, {\"rodada\": 50, \"gamma_damping\": 0.7, \"blocking_efficiency\": 0.536}, {\"rodada\": 50, \"gamma_damping\": 0.8, \"blocking_efficiency\": 0.564}, {\"rodada\": 50, \"gamma_damping\": 0.9, \"blocking_efficiency\": 0.546}, {\"rodada\": 50, \"gamma_damping\": 1.0, \"blocking_efficiency\": 0.562}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(db.groupby(['rodada','gamma_damping'])['blocking_efficiency'].mean().reset_index()).mark_line().encode(\n",
    "      x = 'rodada',\n",
    "      y = 'blocking_efficiency',\n",
    "      color = 'gamma_damping:N', tooltip = ['gamma_damping']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_agent_basic.py', 'ps_agent_flexible.py', '__pycache__']\n",
      "['env_grid_world.py', 'env_invasion_game.py', 'env_invasion_game_lier.py', 'env_neverending_color.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "agent_list = os.listdir('agents')\n",
    "environment_list = os.listdir('environments')\n",
    "\n",
    "print(agent_list)\n",
    "print(environment_list)\n",
    "\n",
    "sys.path.insert(0, 'agents')\n",
    "sys.path.insert(0, 'environments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from  IPython.display import clear_output\n",
    "def grid(dimensions, position):\n",
    "    grid = \"\"\n",
    "    for j in range(dimensions[1]):\n",
    "        for i in range(dimensions[0]):\n",
    "            if ([i,j] == position).all():\n",
    "                grid = grid + '|X'\n",
    "            else:\n",
    "                grid = grid + '| '\n",
    "        grid = grid + '|\\n'\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|X| | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n"
     ]
    }
   ],
   "source": [
    "import env_grid_world as environment_class\n",
    "import ps_agent_basic as agent_class\n",
    "\n",
    "dimensions = [5,5]\n",
    "env = environment_class.TaskEnvironment(dimensions)\n",
    "\n",
    "#parameters for the agent - explanations can be found in the comments inside the agent file\n",
    "gamma_damping = 0\n",
    "eta_glow_damping = 0.12\n",
    "policy_type = 'softmax'\n",
    "beta_softmax = 1\n",
    "num_reflections =  2\n",
    "\n",
    "agent = agent_class.BasicPSAgent(\n",
    "    env.num_actions, env.num_percepts_list, \n",
    "    gamma_damping, eta_glow_damping, \n",
    "    policy_type, beta_softmax, \n",
    "    num_reflections\n",
    ")\n",
    "\n",
    "\"\"\"Initialise and run interaction\"\"\"\n",
    "\n",
    "#set number of trials and maximum number of steps in each trial\n",
    "num_trials = 50\n",
    "max_steps_per_trial = env.max_steps_per_trial\n",
    "\n",
    "print(\"{}\".format(grid(dimensions, env.position)), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103.  26.  26.  27.  19.  11.   9.  22.   9.  13.  10.  15.  10.  11.\n",
      "   8.   8.   8.  10.   8.   8.   8.   8.   8.   8.   8.   8.   8.   8.\n",
      "   8.   8.   8.   8.   8.   8.   8.   8.   8.   8.   8.   8.   8.   8.\n",
      "   8.   8.   8.   8.   8.   8.   8.   8.]\n"
     ]
    }
   ],
   "source": [
    "#initialise a record of performance\n",
    "learning_curve = np.zeros(num_trials)\n",
    "reward = 0 #temporarily stores the reward for the most recent action\n",
    "for i_trial in range(num_trials):\n",
    "    reward_trial = 0 #additive counter of the total rewards earned during the current trial\n",
    "    discretized_observation = env.reset()\n",
    "    for t in range(max_steps_per_trial):\n",
    "        #This is where the heart of the interaction takes place\n",
    "        action = agent.deliberate_and_learn(discretized_observation, reward)\n",
    "        discretized_observation, reward, done = env.move(action)\n",
    "        reward_trial += reward\n",
    "        if done:\n",
    "            break\n",
    "    learning_curve[i_trial] = t+1\n",
    "\n",
    "\"\"\"Return results\"\"\"\n",
    "print(learning_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(grid_), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m     clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 26\u001b[0m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"Return results\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(learning_curve)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#initialise a record of performance\n",
    "learning_curve = np.zeros(num_trials)\n",
    "reward = 0 #temporarily stores the reward for the most recent action\n",
    "for i_trial in range(num_trials):\n",
    "    reward_trial = 0 #additive counter of the total rewards earned during the current trial\n",
    "    discretized_observation = env.reset()\n",
    "    for t in range(max_steps_per_trial):\n",
    "        print(f'Trial {i_trial+1}')\n",
    "        print(f'Step {t+1}')\n",
    "        grid_ = grid(dimensions, env.position)\n",
    "        print(\"{}\".format(grid_), end=\"\")\n",
    "        clear_output(wait=True)\n",
    "        sleep(0.1)\n",
    "        #This is where the heart of the interaction takes place\n",
    "        action = agent.deliberate_and_learn(discretized_observation, reward)\n",
    "        discretized_observation, reward, done = env.move(action)\n",
    "        reward_trial += reward\n",
    "        if done:\n",
    "            break\n",
    "    learning_curve[i_trial] = t+1\n",
    "    print(f'Trial {i_trial+1}')\n",
    "    print(f'Step {t+1}')\n",
    "    grid_ = grid(dimensions, env.position)\n",
    "    print(\"{}\".format(grid_), end=\"\")\n",
    "    clear_output(wait=True)\n",
    "    sleep(1)\n",
    "\n",
    "\"\"\"Return results\"\"\"\n",
    "print(learning_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid World - agente flexivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_agent_basic.py', 'ps_agent_flexible.py', '__pycache__']\n",
      "['env_grid_world.py', 'env_invasion_game.py', 'env_invasion_game_lier.py', 'env_neverending_color.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "agent_list = os.listdir('agents')\n",
    "environment_list = os.listdir('environments')\n",
    "\n",
    "print(agent_list)\n",
    "print(environment_list)\n",
    "\n",
    "sys.path.insert(0, 'agents')\n",
    "sys.path.insert(0, 'environments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from  IPython.display import clear_output\n",
    "def grid(dimensions, position, old_positions = [], paredes = []):\n",
    "    grid = \"\"\n",
    "    for j in range(dimensions[1]):\n",
    "        for i in range(dimensions[0]):\n",
    "\n",
    "            if ([i,j] == position).all():\n",
    "                grid = grid + '|X'\n",
    "            elif ([i,j] in paredes):\n",
    "                grid = grid + '|█'\n",
    "            elif ([i,j] in old_positions[-20:]):\n",
    "                grid = grid + '|.'\n",
    "            else:\n",
    "                grid = grid + '| '\n",
    "        grid = grid + '|\\n'\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0,0],[1,0],[2,0],[3,0],[4,0],[5,0],[6,0],[7,0],[8,0],[9,0],\n",
      "[0,1],[1,1],[2,1],[3,1],[4,1],[5,1],[6,1],[7,1],[8,1],[9,1],\n",
      "[0,2],[1,2],[2,2],[3,2],[4,2],[5,2],[6,2],[7,2],[8,2],[9,2],\n",
      "[0,3],[1,3],[2,3],[3,3],[4,3],[5,3],[6,3],[7,3],[8,3],[9,3],\n",
      "[0,4],[1,4],[2,4],[3,4],[4,4],[5,4],[6,4],[7,4],[8,4],[9,4],\n",
      "[0,5],[1,5],[2,5],[3,5],[4,5],[5,5],[6,5],[7,5],[8,5],[9,5],\n",
      "[0,6],[1,6],[2,6],[3,6],[4,6],[5,6],[6,6],[7,6],[8,6],[9,6],\n",
      "[0,7],[1,7],[2,7],[3,7],[4,7],[5,7],[6,7],[7,7],[8,7],[9,7],\n",
      "[0,8],[1,8],[2,8],[3,8],[4,8],[5,8],[6,8],[7,8],[8,8],[9,8],\n",
      "[0,9],[1,9],[2,9],[3,9],[4,9],[5,9],[6,9],[7,9],[8,9],[9,9],\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printando locais do mapa\n",
    "from time import sleep\n",
    "from  IPython.display import clear_output\n",
    "grid_ = \"\"\n",
    "for j in range(dimensions[1]):\n",
    "        for i in range(dimensions[0]):\n",
    "            grid_ = grid_ + f'[{i},{j}],'\n",
    "        grid_ = grid_ + '\\n'\n",
    "\n",
    "print(grid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|X| | | | | | | | | |\n",
      "|█|█|█|█|█|█|█|█|█| |\n",
      "| | | | | | | | | | |\n",
      "| | |█|█|█|█|█|█|█|█|\n",
      "| | | | | | | | | | |\n",
      "|█|█|█|█|█|█|█|█|█| |\n",
      "| | | | | | | | | | |\n",
      "| |█|█|█|█|█|█|█|█|█|\n",
      "| | | | | | | | | | |\n",
      "|█|█|█|█|█|█|█|█|█| |\n"
     ]
    }
   ],
   "source": [
    "import env_grid_world as environment_class\n",
    "import ps_agent_flexible as agent_class\n",
    "\n",
    "dimensions = [10,10]\n",
    "env = environment_class.TaskEnvironment(dimensions)\n",
    "\n",
    "paredes = []\n",
    "#paredes = [[3,3], [4,3], [5,3], [7,1], [7,2], [7,3], [7,4], [7,5], [7,9], [0,5], [0,6], [0,7], [2,6], [3,6], [4,6], [2,7], [4,7], [5,7], [6,7], [7,7], [7,6], [1,0], [1,1]]\n",
    "#paredes = [[0,1],[1,1],[2,1],[3,1],[4,1],[5,1],[6,1],[7,1],[8,1], [2,3],[3,3],[4,3],[5,3],[6,3],[7,3],[8,3],[9,3], [0,5],[1,5],[2,5],[3,5],[4,5],[5,5],[6,5],[7,5],[8,5],[1,7],[2,7],[3,7],[4,7],[5,7],[6,7],[7,7],[8,7], [9,7], [0,9],[1,9],[2,9],[3,9],[4,9],[5,9],[6,9],[7,9],[8,9]]\n",
    "env.walls = env.walls + paredes\n",
    "\n",
    "#parameters for the agent - explanations can be found in the comments inside the agent file\n",
    "gamma_damping = 0\n",
    "eta_glow_damping = 0.12\n",
    "policy_type = 'softmax'\n",
    "beta_softmax = 1\n",
    "num_reflections =  0\n",
    "\n",
    "agent = agent_class.FlexiblePSAgent(\n",
    "    env.num_actions,\n",
    "    gamma_damping, eta_glow_damping, \n",
    "    policy_type, beta_softmax,\n",
    "    num_reflections\n",
    ")\n",
    "\n",
    "\"\"\"Initialise and run interaction\"\"\"\n",
    "\n",
    "#set number of trials and maximum number of steps in each trial\n",
    "num_trials = 300\n",
    "max_steps_per_trial = env.max_steps_per_trial\n",
    "\n",
    "print(\"{}\".format(grid(dimensions, env.position, [], env.walls)), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1990.  1681.  8643.  2784.  3985.  7013.  2505.  6469.  1236.  3596.\n",
      "  3049.  3121. 12641.  2129.  1137.  3643.   647.  3302.  2380.  1792.\n",
      "  3019.  2262.  3206.  2029.  1632.  1961.  1360.  4143.  6725.  2444.\n",
      "  5918.  1423.  1661.  3842.  3430.   671.  3962.   283.   651.   151.\n",
      "  3384.  1565.  2411.  5221.  1728.   941.  4517.  1057.  1777.   252.\n",
      "  1387.  1168.  8444.  4845.   658.   932.  1174.  2113.   546.   645.\n",
      "  1138.  1009.  2479.   999.   520.  1684.  3724.  1127.   658.   969.\n",
      "  2986.   621.   942.   333.  1749.  1274.  1220.   367.  1997.  1288.\n",
      "   526.  2085.   754.   868.  1278.   696.   408.   760.   786.  2152.\n",
      "  1436.  4777.  1230.   815.  1021.   653.   354.   985.  1241.  2275.\n",
      "  1614.   496.  1620.  1104.  2152.   589.   470.   984.  1385.   912.\n",
      "   551.   649.  2968.   513.  1427.  1429.   927.  1513.   384.  3432.\n",
      "   697.  1471.   732.   357.   619.  3806.   835.  1523.  1741.   887.\n",
      "   293.   277.   666.   428.   717.   838.   347.   251.   652.   978.\n",
      "   981.  1715.   470.  1142.   513.   539.   731.  1267.  1172.  1544.\n",
      "   955.   695.   400.   273.   579.   750.   434.  3115.   390.   420.\n",
      "   491.   221.   350.   204.   122.  2514.   471.  1429.   240.   734.\n",
      "   299.   697.   210.   656.   525.   229.   259.  1846.   220.  2208.\n",
      "   166.   151.   984.  1408.   768.   153.   805.  1006.  1388.  1614.\n",
      "  1753.  1715.   925.   575.   475.  1252.   792.   463.   609.   431.\n",
      "  1289.   650.   969.   663.   388.   522.   438.   685.   811.   824.\n",
      "   472.   586.   636.   811.   274.  1843.   658.   376.   236.  1516.\n",
      "  1041.   168.   537.   150.   392.   606.   534.  1466.  1031.   455.\n",
      "  1186.   546.   436.  1215.   685.   344.   698.   178.   414.   313.\n",
      "   377.   216.   430.   308.   757.   627.   480.   389.   764.   517.\n",
      "   145.   601.   537.  1482.   518.   346.  1023.   722.   329.   460.\n",
      "  1257.   169.   157.   459.   192.   154.   883.   808.  1109.  1232.\n",
      "   355.  1451.   126.   210.  1126.  1242.   206.   812.   425.   809.\n",
      "   671.   529.   281.   588.   351.   765.   522.  1376.  1111.   352.\n",
      "   447.   223.   444.   388.   498.   291.   214.   796.   229.   517.]\n"
     ]
    }
   ],
   "source": [
    "#initialise a record of performance\n",
    "learning_curve = np.zeros(num_trials)\n",
    "reward = 0 #temporarily stores the reward for the most recent action\n",
    "for i_trial in range(num_trials):\n",
    "    reward_trial = 0 #additive counter of the total rewards earned during the current trial\n",
    "    discretized_observation = env.reset()\n",
    "    for t in range(max_steps_per_trial):\n",
    "        #This is where the heart of the interaction takes place\n",
    "        action = agent.deliberate_and_learn(discretized_observation, reward)\n",
    "        discretized_observation, reward, done = env.move(action)\n",
    "        reward_trial += reward\n",
    "        if done:\n",
    "            break\n",
    "    learning_curve[i_trial] = t+1\n",
    "\n",
    "\"\"\"Return results\"\"\"\n",
    "print(learning_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4\n",
      "Step 24\n",
      "|.|.|X| | | | | | | |\n",
      "|█|█|█|█|█|█|█|█|█| |\n",
      "| | | | | | | | | | |\n",
      "| | |█|█|█|█|█|█|█|█|\n",
      "| | | | | | | | | | |\n",
      "|█|█|█|█|█|█|█|█|█| |\n",
      "| | | | | | | | | | |\n",
      "| |█|█|█|█|█|█|█|█|█|\n",
      "| | | | | | | | | | |\n",
      "|█|█|█|█|█|█|█|█|█| |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m old_positions\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlist\u001b[39m(env\u001b[38;5;241m.\u001b[39mposition))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(grid_), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#This is where the heart of the interaction takes place\u001b[39;00m\n\u001b[0;32m     17\u001b[0m action \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mdeliberate_and_learn(discretized_observation, reward)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#initialise a record of performance\n",
    "learning_curve = np.zeros(num_trials)\n",
    "reward = 0 #temporarily stores the reward for the most recent action\n",
    "for i_trial in range(num_trials):\n",
    "    reward_trial = 0 #additive counter of the total rewards earned during the current trial\n",
    "    discretized_observation = env.reset()\n",
    "    old_positions = []\n",
    "    for t in range(max_steps_per_trial):\n",
    "        clear_output(wait=True)\n",
    "        print(f'Trial {i_trial+1}')\n",
    "        print(f'Step {t+1}')\n",
    "        grid_ = grid(dimensions, env.position, old_positions, env.walls)\n",
    "        old_positions.append(list(env.position))\n",
    "        print(\"{}\".format(grid_), end=\"\")\n",
    "        sleep(0.05)\n",
    "        #This is where the heart of the interaction takes place\n",
    "        action = agent.deliberate_and_learn(discretized_observation, reward)\n",
    "        discretized_observation, reward, done = env.move(action)\n",
    "        reward_trial += reward\n",
    "        if done:\n",
    "            break\n",
    "    learning_curve[i_trial] = t+1\n",
    "    sleep(3)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "\"\"\"Return results\"\"\"\n",
    "print(learning_curve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projective-simulation-python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
